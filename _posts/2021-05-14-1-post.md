---
title: "일반화, 과대적합, 과소적합"
date: 2021-01-04 16:22:28 -0400
categories: ml 머신러닝
---
### 일반화
모델이 학습하지 않은 새로운 데이터에 대해 정확하게 예측할 수 있으면 해당 모델은 **일반화(generalization)** 가 잘 되었다고 말한다.

훈련 데이터에 대해 정확하게 예측하도록 모델을 구축하고 모델이 학습하지 않은 테스트 데이터를 사용해 모델의 일반화가 잘 되었는지 평가할 수 있다.

일반적으로 모델이 훈련 데이터를 정확하게 예측하고 훈련 데이터와 데스트 데이터가 매우 비슷하다면 모델이 테스트 데이터에서도 정확히 예측하리라 기대할 수 있다.

하지만 항상 그런 것이 아니며, 아주 복잡한 모델(훈련 데이터에 너무 가깝게 모델을 구축)을 만들었다면 훈련 데이터에만 정확한 모델이 되어버릴 수 있다.

### 과대적합
데이터의 양이 적은 상태에서 가진 정보를 모두 사용해서 너무 복잡한 모델을 만들면 훈련 데이터의 각 샘플에 너무 가깝게 맞춰져서 
새로운 데이터에 대해서는 정확하게 예측하지 못하는 일이 발생할 수 있다.

이를 **과대적합(overfitting)** 이라 하며 모델이 훈련 데이터는 잘 예측하지만 학습하지 않은 새로운 데이터(테스트 데이터)는 잘 예측하지 못하는 것을 말한다.

### 과소적합
과대적합과는 반대로 모델이 너무 간단하면 데이터의 다양성을 잡아내지 못해 훈련 데이터와 테스트 데이터에도 정확하게 예측하지 못하게 되는 일이 발생한다.

이를 **과소적합(underfitting)** 이라 한다.

### 최적의 모델
즉 과대적합과 과소적합이 되지 않고 모델이 학습한 훈련 데이터와 학습하지 않은 신규 테스트 데이터에 대한 예측 성능이 최대가 되는 최적점에 있는 모델(일반화 성능이 최대인 모델)을 찾아야 한다.

### 모델복잡도와 일반화
모델의 복잡도가 커질수록 훈련 데이터에 대한 예측 성능은 좋아지지만 데스트 데이터에 대한 예측 성능이 떨어지는 과대적합이 발생하므로,
훈련 데이터와 테스트 데이터에 대한 예측 성능이 최대가 되는 최적점을 찾아 일반화가 잘 된 모델을 구축해야 한다.

<p align="center"><img src="https://user-images.githubusercontent.com/71070011/103517586-bce36b80-4eb5-11eb-90ae-d692e57d1546.PNG" width="70%" height="70%"></p>
